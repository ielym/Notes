# Gumbel Softmax

本节开始之前，首先思考argmax和softmax：

对于 $softmax = [0.02948882,  0.08015893,  0.21789455,  0.5922988,  0.08015893]$ ，相当如下所示的离散型概率分布模型：

| X     | x=0        | x=1        | x=2        | x=3       | x=4        |
| ----- | ---------- | ---------- | ---------- | --------- | ---------- |
| **P** | 0.02948882 | 0.08015893 | 0.21789455 | 0.5922988 | 0.08015893 |

+ 题外话：

  上述概率分布的均值为：
  $$
  E(X) = \sum_{i=0}^{4} i \times p_i
  $$
  **（可以发现，softmax概率分布的均值即为soft-argmax）**

如果我们想从上表所示的概率分布中采样出一些离散的样本 $X \in \{0, 1, 2, 3\} ^ N$ ，例如采样出的样本为  $\{3, 3, 2, 0\}$ 。显然，$p(x=3)$ 的概率最大，因此采样出的样本也最多。此外，虽然 $p(x=0)$ 的概率较小，但也有一定几率被采样到。

当我们使用 argmax 时，其实也相当于进行采样，只不过每次采样出的样本都是概率最大的。显然，这种方式存在一定不足。如：

+ 以图像分类为例，预测出物体是汽车的概率是 $p(汽车) = 0.9$ ,是火车的概率是 $p(火车) = 0.1$ ，如果使用argmax的话，就只能获得预测类别是汽车这一种固定的类别，这种方式就偏离了概率分布本身所表示的意义了。
+ 在强化学习中，机器人能够按照前后左右四个方向移动，此时我们无法说概率最大的方向一定是最优的。

为了按照概率分布进行随机的采样，我们可以引入一定的随机性。首先介绍第一种方法 `np.random.choice` ：

+ 为了按照上表所示的离散型随机变量的概率分布进行采样，coding中可以使用如下代码：

  ```python
  import numpy as np
  
  x = [0, 1, 2, 3, 4]
  p = [0.02948882,  0.08015893,  0.21789455,  0.5922988,  0.08015893]
  
  result = []
  for _ in range(1000):
      sample = np.random.choice(x, 1, p=p)
      result.append(int(sample))
  
  result = np.array(result)
  
  print(np.sum(result == 3) / len(result))
  
  # 0.593
  ```

然而，这种采样方法是不可导的。如果我们需要在具有BP的模型中的某个中间环节引入采样过程，则无法计算梯度（如强化学习中采样后还需要让机器人移动，从而才能计算梯度）。

因此，是否有一种具有表达式的函数 $f$ ，能够使我们通过一些有具体表达式的计算来模拟该采样过程呢？如：

+ 第一次采样 ： $f(...) = 3$
+ 第二次采样 ： $f(...) = 3$
+ 第三次采样 ： $f(...) = 2$
+ ...

如果可以找到这样的函数 $f$ ，且 $f$ 可导，就能够实现我们的目标：既能够按照概率分布进行随机采样，又能够计算导数，使其能够加入到具有BP的模型中。

